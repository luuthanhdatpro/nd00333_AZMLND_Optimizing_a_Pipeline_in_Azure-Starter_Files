# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Useful Resources
- [ScriptRunConfig Class](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.scriptrunconfig?view=azure-ml-py)
- [Configure and submit training runs](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-set-up-training-targets)
- [HyperDriveConfig Class](https://docs.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.hyperdrive.hyperdriveconfig?view=azure-ml-py)
- [How to tune hyperparamters](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-tune-hyperparameters)


## Summary
The dataset includes bank customer attributes, credit status and did the customer apply for a time deposit? The data set contains the following information.
The goal of the classification is to predict whether a customer will apply for a time deposit with the bank.

The classification model with the best prediction accuracy is the VotingEnsemble built with AutoML.

## Scikit-learn Pipeline
**Pipeline architecture**
The csv file was registered in the dataset and the two hyperparameters of logistic regression (Regularization Strength, Max iterations) were tuned.

**What are the benefits of the parameter sampler you chose?**
The sampler is RandomParameterSampling. The benefit of this algorithm is that it can sample the entire search space at high speed.

**What are the benefits of the early stopping policy you chose?**
BanditPolicy was adopted for the early stopping policy.
The three advantages of this method are as follows
* Training can proceed more effectively because resources are not wasted on trials with low performance. This reduces costs and time.
* The ability to quickly stop a bad trial while other trials are still running allows for redistribution of computational resources to promising trials.
* Flexible control of stopping criteria by adjusting the Slack Factor and Evaluation Interval, which can be optimized for specific use cases.

## AutoML
The model generated by AutoML is a scaling (MaxAbsScaler, SparseNormalizer, StandardScalerWrapper, TruncatedSVDWrapper), LightGBM, SGD, ExtremeRandomTrees, LogisticRegression, XGBoostClassifier combination
and VotingEnsemble, and StackEnsemble. Detail is below.
* MaxAbsScaler 
  * LightGBM
  * SGD
  * ExtremeRandomTrees
  * LogisticRegression
  * XGBoostClassifier
* SparseNormalizer
  * LightGBM
  * RandomForest
  * XGBoostClassifier
* StandardScalerWrapper
  * LightGBM
  * ExtremeRandomTrees
  * RandomForest
  * LogisticRegression
  * XGBoostClassifier
* TruncatedSVDWrapper 
  * RandomForest
* VotingEnsemble
* StackEnsemble

## Pipeline comparison between sklearn and AutoML
I Compared the two logistic regression model and their performance.
* Difference METRIC between ITER 7 and ITER 12: Differences in metrics are estimated as differences in hyperparameters
* Difference METRIC between ITER 7 and ITER 16: Differences in metrics are estimated as differences in scaling methods
* Difference METRIC between ITER 12 and ITER 16: Differences in metrics are estimated as differences in scaling methods

| ITER |  PIPELINE | METRIC |
|---|---|---|
|    7 |  MaxAbsScaler LogisticRegression | 0.9082 | 
|   12 |  MaxAbsScaler LogisticRegression | 0.9087 |
|   16 |  StandardScalerWrapper LogisticRegression |0.9093 |

## Future work
Assuming the next experiment is based on the accuracy of the forecasting model and actual use cases, the following three improvements were assumed
* Time deposit applications are unbalanced at 11.2%, so corrected to equilibrium data
* Feature engineering such as binning of duration
* Revision of metrics from accuracy to recall/ROC, etc.